## 《大数据时代--生活、工作与思维方式变革》第二章读书笔记1
### 二、更杂：不是精确性，而是混杂性
- （1）执迷于精确性是信息缺乏时代和模拟时代的产物。只有5%的数据是结构化且能适用于传统数据库的。如果不接受混乱，剩下95%的非结构化数据都无法被利用。
##### 1、允许不精确
- （1）在不断涌现的新情况里，**允许不精确的出现已经成为一个新的亮点**，而非缺点。因为放松了容错的标准，人们掌握的数据也多了起来，还可以利用这些数据做更多新的事情。
- （2）混乱，随着数据的增加，错误率也会相应增加。
- （3）在整合来源不同的各类信息的时候，因为它们通常不完全一致，所以也会加大混乱程度。
- （4）例如，与服务器处理投诉时的数据进行比较，用语音识别系统识别某个呼叫中心接到的投诉会产生一个不太准确的结果，但也是有助于我们把握整个事情的大致情况的。
- （5）混乱还可以指格式的不一致性，因为要达到格式一致，就需要在进行数据处理之前仔细地清洗数据，而这在大数据背景下很难做到。
- （6）当然，在萃取或处理数据的时候，混乱也会发生。因为在进行数据转化的时候，我们是在把它变成另外的事物。比如，我们在对Twitter的信息进行情感分析来预测好莱坞票房的时候，就会出现一定的混乱。
- （7）虽然我们得到的信息不再那么准确，但收集到的数量庞大的信息让我们放弃严格精确的选择变得更为划算。
- （8）**“大数据”通常用概率说话**，而不是板着“确凿无疑”的面孔。当我们试图扩大数据规模的时候，要学会拥抱混乱。
- （9）**摩尔定律：**每块芯片上晶体管的数量每两年就会翻一倍。这使得电脑运行更快速了，存储空间更大了。
- （10）大数据在多大程度上优于算法这个问题在自然语言处理上表现得很明显。
> A、在2000年的时候，微软研究中心的米歇尔·班科（Michele Banko）和埃里克·布里尔（Eric Bill）一直在寻求改进Word程序中语法检查的方法。最后，他们决定往4种常见的算法中逐渐添加数据，先是一千万字，再到一亿字，最后到十亿。
- （11）计算机象棋程序总是步步为赢，是因为往系统里加入了更多的数据。所以，计算机在这些重要的象棋残局中表现得完美无缺和不可战胜。
- （12）社会从“大数据”中所能得到的，并非来自运行更快的芯片或更好的算法，而是更多的数据。
#####三、大数据的简单算法比小数据的复杂算法更有效
- （1）1954年，IBM以计算机中的250个词语和六条语法规则为基础，将60个俄语词组翻译成了英语，结果振奋人心。
- （2）20世纪80年代后期，他们试图让计算机自己估算一个词或一个词组适合于用来翻译另一种语言中的一个词和词组的可能性，然后再决定某个词和词组在另一种语言中的对等词和词组。
- （3）20世纪90年代，将大约有300万句之多的加拿大议会资料译成了英语和法语并出版。
> IBM公司尽管投入了很多资金，但取得的成效不大。

- （4）无所不包的谷歌翻译系统：它将语言视为能够判别可能性的数据，数据库涵盖了60多种语言，甚至能够接受14种语言的语音输入，并有很流利的对等翻译。
- （5）谷歌的翻译之所以更好并不是因为它拥有一个更好的算法机制。谷歌翻译增加了很多各种各样的数据。从谷歌的例子来看，它之所以能比IBM的Candide系统多利用成千上万的数据，是因为它接受了有错误的数据。

      关于无所不包的谷歌翻译系统案例（考题）
      ①、谷歌数据库有很流利的对等翻译，是因为它将语言视为能够判别可能性的数据，而不是语言本身。
      ②、在翻译的时候谷歌能适当增减词汇，所以它比其他系统的翻译灵活很多。
- （6）《数据的非理性效果》（The Unreasonable Effectiveness of Data）的文章中写道，“大数据基础上的简单算法比小数据基础上的复杂算法更加有效。彼得·诺维格（Peter Norvig）”就指出，混杂是关键。
##### 四、纷繁的数据越多越好
- （1）大数据时代要求我们重新审视精确性的优劣。所以，我们需要确保每个数据的精确性，才不会导致分析结果的偏差。
- （2）我们要做的就是要接受这些纷繁的数据并从中受益，而不是以高昂的代价消除所有的不确定性。
- （3）大数据不仅让我们不再期待精确性，也让我们无法实现精确性。
- （4）值得注意的是，错误性并不是大数据本身固有的。它只是我们用来测量、记录和交流数据的工具的一个缺陷。

      例子：麻省理工与通货紧缩预测软件：（关于麻省理工与通货紧缩预测软件的案例说法）--考题：
      A、阿尔贝托·卡瓦略（Alberto Cavell）和罗伯托·里哥本（Oberto Rigobon）就对通货紧缩提出了一个大数据方案，那就是接受更混乱的数据。在2008年9月雷曼兄弟破产之后马上就发现了通货紧缩趋势。
      B、对投资者和商家来说消费物价指数（CPI）是非常重要，这是用来测试通货膨胀率的。 
#####五、混杂性，不是竭力避免，而是标准途径
> ①、几个世纪以来，人们一直用分类法和索引法来帮助自己存储和检索数据资源。这样的分级系统通常都不完善，一旦把数据规模增加好几个数量级，这些预设一切都各就各位的系统就会崩溃。
②、相片分享网站Flickr会给照片添加标签，清楚的分类被更混乱却更灵活的机制所取代了。因为它们的存在，互联网上的资源变得更加容易找到，特别是像图片、视频和音乐这些无法用关键词搜索的非文本类资源。

- （1）清楚的分类被更混乱却更灵活的机制所取代了。这些机制才能适应改变着的世界。
- （2）我们添加标签时所固带的不准确性从某种意义上说明我们能够接受世界的纷繁复杂。这是对更加精确系统的一种对抗。
- （3）这些精确的系统试图让我们接受一个世界贫乏而规整的惨象——假装世间万物都是整齐地排列的。而事实上现实是纷繁复杂的，天地间存在的事物也远远多于系统所设想的。
- （4）互联网上最火的网址都表明，它们欣赏不精确而不会假装精确。
- （5）要想获得大规模数据带来的好处，混乱应该是一种标准途径，而不应该是竭力避免的。
- （6）我们甚至发现，不精确已经渗入了数据库设计这个最不能容忍错误的领域。
##### 六、新的数据库设计的诞生
- （1）帕特·赫兰德（Pat Helland）在一篇题为《如果你有足够多的数据，那么“足够好”真的足够好》的文章中，分析了被各种各样质量参差不齐的数据所侵蚀的传统数据库设计的核心原则，他认为，处理海量数据会不可避免地导致部分信息的缺失。虽然这本来就是有“损耗性”的，但是能快速得到想要的结果弥补了这个缺陷。

      （例子）Hadoop与VISA的13分钟：能够将处理两年内730亿单交易所需的时间，从一个月缩减至仅仅13分钟。
        A、Hadoop的输出结果对于不要求极端精确的任务，它就比其他系统运行得快很多。
        B、Hadoop假定了数据量的巨大使得数据完全无法移动，所以人们必须在本地进行数据分析。
- （2）相比依赖于小数据和精确性的时代，大数据因为更强调数据的完整性和混杂性，帮助我们进一步接近事实的真相。
